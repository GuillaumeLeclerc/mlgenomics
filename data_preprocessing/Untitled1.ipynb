{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "\n",
    "from __future__ import print_function\n",
    "from scipy.spatial import ConvexHull\n",
    "from skimage.transform import downscale_local_mean\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "from skimage.measure import regionprops\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os as os\n",
    "from tqdm import tqdm as tqdm_base\n",
    "def tqdm(*args, **kwargs):\n",
    "    if hasattr(tqdm_base, '_instances'):\n",
    "        for instance in list(tqdm_base._instances):\n",
    "            tqdm_base._decr_instances(instance)\n",
    "    return tqdm_base(*args, **kwargs)\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# define functions\n",
    "\n",
    "# function from here: https://github.com/weallen/STARmap/blob/master/python/analysis.py\n",
    "def load_data(data_dir, prefix=\"Cell\"):\n",
    "        #expr = pd.read_csv(os.path.join(data_dir, \"data_table.csv\"), index_col=0)\n",
    "    expr = pd.read_csv(os.path.join(data_dir, \"cell_barcode_count.csv\"), header=None)\n",
    "    gene_names = pd.read_csv(os.path.join(data_dir, \"cell_barcode_names.csv\"),header=None)\n",
    "    rownames = [i for i in range(expr.shape[0])]\n",
    "    names = gene_names[2]\n",
    "    names.name = \"Gene\"\n",
    "    return pd.DataFrame(data=expr.values, columns=names, index=rownames)\n",
    "\n",
    "# function from https://github.com/weallen/STARmap/blob/master/python/viz.py\n",
    "def GetQHulls(labels):\n",
    "    labels += 1\n",
    "    Nlabels = labels.max()\n",
    "    hulls = []\n",
    "    coords = []\n",
    "    num_cells = 0\n",
    "    #cell_id = []\n",
    "    #print('blah')\n",
    "    for i in tqdm(range(Nlabels)):#enumerate(regionprops(labels)):\n",
    "        #print(i,\"/\",Nlabels)\n",
    "        curr_coords = np.argwhere(labels==i) # get all coordinates for a single cell label\n",
    "        # size threshold of > 100 pixels and < 100000\n",
    "        if curr_coords.shape[0] < 100000 and curr_coords.shape[0] > 1000: # if the cell shape is within threshold region, save the coordinates\n",
    "            num_cells += 1\n",
    "            hulls.append(ConvexHull(curr_coords))\n",
    "            coords.append(curr_coords)\n",
    "        #cell_id = np.append(cell_id, i)\n",
    "    #print(\"Used %d / %d\" % (num_cells, Nlabels))\n",
    "    return hulls, coords\n",
    "\n",
    "## my functions:\n",
    "def normalize(counts):\n",
    "\n",
    "    cts = np.array(counts)\n",
    "    index = np.array(np.where(np.sum(cts, axis = 1)!=0)).flatten()\n",
    "    cts = cts[index,:] # remove cells, where total library count is zero\n",
    "    cell_sum = np.sum(cts, axis = 1) # get row-wise sum\n",
    "    counts_out = cts/(np.tile(cell_sum, (cts.shape[1],1)).transpose()) # divide each column by row-wise sum\n",
    "\n",
    "    return counts_out, index\n",
    "\n",
    "def process_2D(data_dir, gene_names,i):\n",
    "\n",
    "    # load data\n",
    "    image = np.load(os.path.join(data_dir,'labels.npz'))[\"labels\"]\n",
    "    counts = load_data(data_dir, prefix=\"\")\n",
    "\n",
    "    # process counts\n",
    "    normalized_counts, index = pd.DataFrame(normalize(counts)) # normalize counts\n",
    "    normalized_counts.columns = counts.columns\n",
    "    normalized_counts = normalized_counts.reindex(columns = sorted(gene_names))\n",
    "    normalized_counts = np.array(normalized_counts.fillna(0))\n",
    "\n",
    "    # get coords\n",
    "    qhulls,coords = GetQHulls(image)# get all coordinates corresponding to single cell\n",
    "    all_centroids  = np.vstack([np.append(c.mean(0),(0,i)) for c in coords]) # centroids are the average coordinates\n",
    "    all_centroids = all_centroids[index,:]\n",
    "    counts_and_coords = np.concatenate((normalized_counts, all_centroids.astype('int')[range(normalized_counts.shape[0]),:]), axis = 1) # concat counts and coords\n",
    "\n",
    "    return counts_and_coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#def process_3D()\n",
    "\n",
    "#  get union of all gene names (across 3D and 2D datasets)\n",
    "genenames_3D = pd.read_csv('/Users/work/Documents/GitHub/mlgenomics/data_as_downloaded/sequentially_encoded_Wang_et_al_2018/gene_names.csv', header = 0)\n",
    "\n",
    "dirs = os.listdir('/Users/work/Documents/GitHub/mlgenomics/data_as_downloaded/combinatorially_encoded/all_datasets')\n",
    "\n",
    "ct = []\n",
    "\n",
    "for i in range(len(dirs)):\n",
    "\n",
    "    data_dir1 = os.path.join('/Users/work/Documents/GitHub/mlgenomics/data_as_downloaded/combinatorially_encoded/all_datasets',dirs[i])\n",
    "\n",
    "    ct.append(load_data(data_dir1, prefix=\"\"))\n",
    "\n",
    "genenames = []\n",
    "for i in range(len(dirs)):\n",
    "    genenames.append(ct[i].columns)\n",
    "\n",
    "all_genes = np.unique(np.concatenate((np.unique(np.concatenate(genenames)),(np.array(genenames_3D).flatten()))))\n",
    "\n",
    "# process and append all the 2D datasets to one another\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.00364964, ..., 0.        , 0.        ,\n",
       "         0.00364964],\n",
       "        [0.        , 0.        , 0.003125  , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([   0,    1,    2, ..., 1546, 1547, 1548]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    data_dir = os.path.join('/Users/work/Documents/GitHub/mlgenomics/data_as_downloaded/combinatorially_encoded/all_datasets',dirs[0])\n",
    "dnormalize(load_data(data_dir, prefix=\"Cell\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4f92a265d611>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/work/Documents/GitHub/mlgenomics/data_as_downloaded/combinatorially_encoded/all_datasets'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdirs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdata_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_genes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# save data out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-9259ac07f625>\u001b[0m in \u001b[0;36mprocess_2D\u001b[0;34m(data_dir, gene_names, i)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# process counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mnormalized_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# normalize counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mnormalized_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mnormalized_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalized_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgene_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "\n",
    "data_out = []\n",
    "\n",
    "for i in range(len(dirs)):\n",
    "    data_dir = os.path.join('/Users/work/Documents/GitHub/mlgenomics/data_as_downloaded/combinatorially_encoded/all_datasets',dirs[i])\n",
    "    data_out.append(process_2D(data_dir, all_genes,i))\n",
    "\n",
    "# save data out\n",
    "np.save('Wang_2018_all_2D_processed_new.npy',data_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    image = np.load(os.path.join(data_dir,'labels.npz'))[\"labels\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image/image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
